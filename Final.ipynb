{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import full_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting MATLAB engine...\n",
      "-------------------------\n",
      "Elapsed: 148.98 sec\n"
     ]
    }
   ],
   "source": [
    "full_model.eng = full_model.start_matlab()\n",
    "show_plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try various Hyperparameter tuning methods\n",
    "* [Scikit-Optimize](https://scikit-optimize.github.io/notebooks/hyperparameter-optimization.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.utils import use_named_args\n",
    "from copy import copy\n",
    "\n",
    "def objective(hyper_params):\n",
    "    global fixed_params_\n",
    "    fixed_params_copy = copy(fixed_params_)\n",
    "    fixed_params_copy.pop('n_rand')\n",
    "    @use_named_args(fixed_params_copy.pop('space'))\n",
    "    def internal(**hyper_params):\n",
    "        global seed_, verb_model_\n",
    "        try:\n",
    "            return 1-fixed_params_copy.pop('model')(**fixed_params_copy, **hyper_params, verbose=verb_model_)[0]\n",
    "        except Exception as ex:\n",
    "            if(type(ex) == KeyError):\n",
    "                raise ex\n",
    "            print(\"Caught a \" + type(ex).__name__ + \". Returning 1.0\")\n",
    "            return 1\n",
    "    return internal(hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.plots import plot_convergence\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def opt_stats(res, start_time=None):\n",
    "    print(\"------------------\")\n",
    "    for i in range(10, len(res.func_vals)+1, 10):\n",
    "        print(\"{0:d}: {1:.4f}\".format(i, min(res.func_vals[0:i])))\n",
    "    print(\"Best score: {0:.4f}\".format(res.fun))\n",
    "    print(\"Best parameters: {0:}\".format(res.x))\n",
    "    if(start_time is not None):\n",
    "        print(\"Total time elapsed: {0:.2f} sec\\n\".format(time.time()-start_time))\n",
    "\n",
    "def opt_plot(res):\n",
    "    global show_plot\n",
    "    plot = plot_convergence(res, yscale='log')\n",
    "    if(show_plot):\n",
    "        plt.show(plot)\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize, dummy_minimize, forest_minimize, gbrt_minimize\n",
    "import time\n",
    "\n",
    "def optimize(function, fixed_params, iterations, random_seed, verb_model=False, verb=True):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # global b/c I couldn't find a better way to directly pass these to the objective function\n",
    "    global fixed_params_, seed_, verb_model_\n",
    "    fixed_params_ = fixed_params\n",
    "    seed_ = random_seed\n",
    "    verb_model_ = verb_model\n",
    "    \n",
    "    # kwargs b/c dummy_minimize can not take n_jobs\n",
    "    optfunc_params = {'n_calls':iterations, 'random_state':random_seed, 'verbose':verb}\n",
    "    if(function != dummy_minimize):\n",
    "        optfunc_params['n_random_starts'] = fixed_params['n_rand']\n",
    "        optfunc_params['n_jobs'] = -1\n",
    "    result = function(objective, fixed_params['space'], **optfunc_params)\n",
    "    if(verb):\n",
    "        opt_plot(result)\n",
    "        print()\n",
    "    opt_stats(result, start_time)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from skopt.learning import GaussianProcessRegressor\n",
    "from skopt.optimizer import base_minimize\n",
    "from sklearn.utils import check_random_state\n",
    "import warnings\n",
    "\n",
    "def func_new(hyper_params):\n",
    "    global func_, xs_, ys_\n",
    "    if(len(xs_) > 0):\n",
    "        y = ys_.pop(0)\n",
    "        if(hyper_params != xs_.pop(0)):\n",
    "            warnings.warn(\"Deviated from expected value, re-evaluating\", RuntimeWarning)\n",
    "        else:\n",
    "            return y\n",
    "    return func_(hyper_params)\n",
    "\n",
    "def reload(result, fixed_params, addtl_iters, random_seed, verb_model=False, verb=True):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # since objective relies on global variables, set them again\n",
    "    global fixed_params_, seed_, verb_model_\n",
    "    fixed_params_ = fixed_params\n",
    "    seed_ = random_seed\n",
    "    verb_model_ = verb_model\n",
    "    \n",
    "    # retrieve optimization call's arguments\n",
    "    args = deepcopy(result.specs['args'])\n",
    "    args['n_calls'] += addtl_iters\n",
    "    args['verbose'] = verb\n",
    "    \n",
    "    # global b/c I couldn't find a better way to pass\n",
    "    global func_, xs_, ys_\n",
    "    func_ = args['func']\n",
    "    xs_ = list(result.x_iters)\n",
    "    ys_ = list(result.func_vals)\n",
    "    args['func'] = func_new\n",
    "    \n",
    "    # recover initial random_state\n",
    "    if(isinstance(args['random_state'], np.random.RandomState)):\n",
    "        args['random_state'] = check_random_state(random_seed)\n",
    "        # if gp_minimize\n",
    "        if(isinstance(result.specs['args']['base_estimator'], GaussianProcessRegressor)):\n",
    "            args['random_state'].randint(0, np.iinfo(np.int32).max)\n",
    "    \n",
    "    # run the optimization\n",
    "    result_new = base_minimize(**args)\n",
    "    \n",
    "    # change the function back, to reload multiple times\n",
    "    result_new.specs['args']['func'] = func_\n",
    "    \n",
    "    if(verb):\n",
    "        opt_plot(result_new)\n",
    "        print()\n",
    "    opt_stats(result_new, start_time)\n",
    "    return result_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer\n",
    "\n",
    "all_params = [\n",
    "    {'model':full_model.run_model, 'dataset':'YaleB', 'n_rand':10, 'epochs_pretrain':201 , 'epochs':101, 'space':\n",
    "         [Real(10**-2, 10**0, \"log-uniform\", name='lr_pretrain'),\n",
    "          Real(10**-3, 10**-1, \"log-uniform\", name='lr'),\n",
    "          Real(10**0, 10**2, \"log-uniform\", name='alpha1'),\n",
    "          Integer(2, 32, name='maxIter1'),\n",
    "          Real(10**0, 10**2, \"log-uniform\", name='alpha2'),\n",
    "          Integer(2, 32, name='maxIter2')]},\n",
    "    {'model':full_model.run_model, 'dataset':'YaleB', 'n_rand':10, 'epochs_pretrain':201 , 'epochs':101, 'space':\n",
    "         [Real(10**-2, 10**0, \"log-uniform\", name='lr_pretrain'),\n",
    "          Real(10**-3, 10**-1, \"log-uniform\", name='lr'),\n",
    "          Real(10**0, 10**2, \"log-uniform\", name='alpha1'),\n",
    "          Integer(10, 32, name='maxIter1'),\n",
    "          Real(10**0, 10**2, \"log-uniform\", name='alpha2'),\n",
    "          Integer(10, 32, name='maxIter2')]},\n",
    "    {'model':full_model.run_model, 'dataset':'Coil20', 'n_rand':10, 'epochs_pretrain':201 , 'epochs':101, 'space':\n",
    "         [Real(10**-4, 10**0, \"log-uniform\", name='lr_pretrain'),\n",
    "          Real(10**-5, 10**-1, \"log-uniform\", name='lr'),\n",
    "          Real(10**-1, 10**3, \"log-uniform\", name='alpha1'),\n",
    "          Integer(10, 100, name='maxIter1'),\n",
    "          Real(10**-1, 10**3, \"log-uniform\", name='alpha2'),\n",
    "          Integer(10, 100, name='maxIter2')]},\n",
    "    {'model':full_model.run_model, 'dataset':'Coil20', 'n_rand':10, 'epochs_pretrain':1001 , 'epochs':251, 'space':\n",
    "         [Real(10**-4, 10**0, \"log-uniform\", name='lr_pretrain'),\n",
    "          Real(10**-5, 10**-1, \"log-uniform\", name='lr'),\n",
    "          Real(10**-1, 10**3, \"log-uniform\", name='alpha1'),\n",
    "          Integer(10, 200, name='maxIter1'),\n",
    "          Real(10**-1, 10**3, \"log-uniform\", name='alpha2'),\n",
    "          Integer(10, 200, name='maxIter2')]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "def get_params(scenario):\n",
    "    fixed_params = copy(all_params[scenario])\n",
    "    data_loaded = full_model.loadmat(\"./saved/processed/\" + fixed_params.pop('dataset'))\n",
    "    fixed_params['images_norm'] = data_loaded['X']\n",
    "    fixed_params['labels'] = data_loaded['Y'].reshape(-1)\n",
    "    return fixed_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = optimize(gp_minimize, get_params(2), 13, 0, verb_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import load\n",
    "\n",
    "gp_loaded = load(\"optims/scenario\" + str(3) + \"/gp_\" + str(0) + \"_\" + str(50) + \".opt\")\n",
    "gp = reload(gp_loaded, get_params(3), 3, 0, verb_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skopt import dump\n",
    "\n",
    "def optimize_multiple(scenario, iterations, seeds=range(5),\n",
    "                      functions={\"gp\":gp_minimize, \"dummy\":dummy_minimize, \"forest\":forest_minimize, \"gbrt\":gbrt_minimize},\n",
    "                      verb_model=False, verb=False):\n",
    "    fixed_params = get_params(scenario)\n",
    "    if(not os.path.isdir(\"optims/scenario\" + str(scenario))):\n",
    "        os.mkdir(\"optims/scenario\" + str(scenario))\n",
    "\n",
    "    for seed in seeds:\n",
    "        print(\"Seed: \" + str(seed))\n",
    "        for func_name in function_dict.keys():\n",
    "            print(func_name + ':')\n",
    "            result = optimize(function_dict[func_name], fixed_params, iterations, seed, verb_model=verb_model, verb=verb)\n",
    "            dump(result, \"optims/scenario\" + str(scenario) + '/' + func_name + '_' + str(seed) + \"_\" + str(iterations) + \".opt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from skopt import dump, load\n",
    "\n",
    "def reload_multiple(scenario, init_iters, addtl_iters, seeds=range(5), func_names=[\"gp\", \"dummy\", \"forest\", \"gbrt\"], verb_model=False, verb=False)\n",
    "    fixed_params = get_params(scenario)\n",
    "    for seed in seeds:\n",
    "        print(\"Seed: \" + str(seed))\n",
    "        for func_name in function_names:\n",
    "            print(func_name + ':')\n",
    "            result_loaded = load(\"optims/scenario\" + str(scenario) + '/' + func_name + '_' + str(seed) + \"_\" + str(init_iters) + \".opt\")\n",
    "            result = reload(result_loaded, fixed_params, addtl_iters, seed, verb_model=verb_model, verb=verb)\n",
    "            dump(result, \"optims/scenario\" + str(scenario) + '/' + func_name + '_' + str(seed) + \"_\" + str(init_iters+addtl_iters) + \".opt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = {'fun', 'space', 'x', 'func_vals', 'x_iters'}\n",
    "def test(val1, val2):\n",
    "    assert np.alltrue([np.alltrue(val1[key] == val2[key]) for key in tests]), \"TESTS FAILED\"\n",
    "    print(\"ALL TESTS PASSED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_func = forest_minimize\n",
    "seed = 1234\n",
    "res1 = optimize(used_func, 12, 1, 1, seed)\n",
    "res1_copy = deepcopy(res1)\n",
    "res12 = reload(res1, 4, seed)\n",
    "res23 = reload(res12, 4, seed)\n",
    "res13 = reload(res1, 8, seed)\n",
    "res3 = optimize(used_func, 20, 1, 1, seed)\n",
    "\n",
    "from skopt import dump, load\n",
    "dump(res1, \"temp.txt\")\n",
    "res1_loaded = load(\"temp.txt\")\n",
    "res12_loaded = reload(res1_loaded, 4, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL TESTS PASSED!\n",
      "ALL TESTS PASSED!\n",
      "ALL TESTS PASSED!\n",
      "ALL TESTS PASSED!\n",
      "ALL TESTS PASSED!\n"
     ]
    }
   ],
   "source": [
    "test(res13, res3)\n",
    "test(res23, res3)\n",
    "test(res1, res1_loaded)\n",
    "test(res12, res12_loaded)\n",
    "test(res1_copy, res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
