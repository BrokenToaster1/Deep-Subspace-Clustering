{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Coil20 data\n",
    "## Extract DSIFT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\aleks_000\\\\Desktop\\\\Mentorship\\\\!GitHub'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matlab.engine\n",
    "eng = matlab.engine.start_matlab()\n",
    "eng.cd(\"./SSC_ADMM_v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Coil20...\n",
      "----------------\n",
      "Elapsed: 3.07 sec\n"
     ]
    }
   ],
   "source": [
    "from load import load_Coil20\n",
    "from img2matrix import single_img2dsift\n",
    "\n",
    "images_raw, labels = load_Coil20()\n",
    "images_dsift = [single_img2dsift(image) for image in images_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(images_raw[0].reshape((-1, 128)));\n",
    "ax[1].imshow(images_dsift[0].reshape((-1, 128)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(np.mean(images_raw, axis=0).reshape((-1, 128)));\n",
    "ax[1].imshow(np.mean(images_dsift, axis=0).reshape((-1, 128)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "idx = 0\n",
    "\n",
    "ax[0].imshow(np.mean(images_raw[72*idx:72*(idx+1)], axis=0).reshape((-1, 128)));\n",
    "ax[1].imshow(np.mean(images_dsift[72*idx:72*(idx+1)], axis=0).reshape((-1, 128)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(np.std(images_raw, axis=0).reshape((-1, 128)));\n",
    "ax[1].imshow(np.std(images_dsift, axis=0).reshape((-1, 128)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import tSNE_2D, tSNE_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_raw_flat = images_raw.reshape(images_raw.shape[0], -1)\n",
    "tSNE_2D(images_raw_flat, labels)\n",
    "tSNE_3D(images_raw_flat, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tSNE_2D(images_dsift, labels)\n",
    "tSNE_3D(images_dsift, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "    \n",
    "pca = PCA(n_components=300, whiten=False, svd_solver='arpack', random_state=0)\n",
    "#images_pca = pca.fit_transform(np.concatenate((1*images_raw, 10*images_dsift), axis=1))\n",
    "images_pca = pca.fit_transform(images_dsift)\n",
    "\n",
    "images_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, height, width):\n",
    "    print(np.min(image), np.max(image))\n",
    "    imgplot = plt.imshow(image.reshape((height, width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# these are reduced parameters - not supposed to look like anything\n",
    "display_image(images_pca[0], 10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(np.mean(images_pca, axis=0), 10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_image(np.std(images_pca, axis=0), 10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tSNE_2D(images_pca, labels)\n",
    "tSNE_3D(images_pca, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize PCA output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types:\n",
    "# feature-wise - normalization occurs along one pixel of all images\n",
    "# image-wise - normalization occurs along all pixels of one image\n",
    "# all - normalization occurs along all pixels of all images\n",
    "\n",
    "# Methods:\n",
    "# standard - mean is set to 0, std is set to 1\n",
    "# [-1, 1] - min and max are used to linearly change the data range to [-1, 1]\n",
    "# unit-vector - each bin is divided by its euclidean distance\n",
    "\n",
    "#[BAD] feature, standard\n",
    "#images_norm = (images_pca - np.mean(images_pca, axis=0)) / np.std(images_pca, axis=0)\n",
    "# image, standard\n",
    "#images_norm = (images_pca - np.mean(images_pca, axis=1)[:, np.newaxis]) / np.std(images_pca, axis=1)[:, np.newaxis]\n",
    "# all, standard\n",
    "#images_norm = (images_pca - np.mean(images_pca)) / np.std(images_pca)\n",
    "\n",
    "\n",
    "#[BAD] feature, [-1, 1]\n",
    "#mmin = np.min(images_pca, axis=0)\n",
    "#mmax = np.max(images_pca, axis=0)\n",
    "#[BAD] image, [-1, 1]\n",
    "#mmin = np.min(images_pca, axis=1)[:, np.newaxis]\n",
    "#mmax = np.max(images_pca, axis=1)[:, np.newaxis]\n",
    "# all, [-1, 1]\n",
    "mmin = np.min(images_pca)\n",
    "mmax = np.max(images_pca)\n",
    "# FOR ALL:\n",
    "images_norm = (2*images_pca - mmax - mmin) / (mmax - mmin)\n",
    "\n",
    "#[BAD] feature, unit\n",
    "#images_norm = images_pca / np.sqrt(np.sum(images_pca*images_pca, axis=0))\n",
    "# image, unit\n",
    "#images_norm = images_pca / np.sqrt(np.sum(images_pca*images_pca, axis=1))[:, np.newaxis]\n",
    "# all, unit\n",
    "#images_norm = images_pca / np.sqrt(np.sum(images_pca*images_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# these are reduced parameters - not supposed to look like anything\n",
    "display_image(images_norm[0], 10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(np.mean(images_norm, axis=0), 10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_image(np.std(images_norm, axis=0), 10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tSNE_2D(images_norm, labels)\n",
    "tSNE_3D(images_norm, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate C matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import supporting_files.sda as sda\n",
    "\n",
    "from supporting_files.helpers import optimize\n",
    "from scipy.io import savemat, loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matlab SSC #1\n",
    "savemat('./temp.mat', mdict={'X': images_norm})\n",
    "k = len(np.unique(labels))\n",
    "alpha = 100.0\n",
    "maxIter = 2\n",
    "eng.SSC_modified(k, 0, False, alpha, False, 1, 1e-20, maxIter, False)\n",
    "C = loadmat(\"./temp.mat\")['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_image(C[:100, :100], 100, 100)\n",
    "print(np.mean(np.square(C)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(np.matmul(C, images_norm)[0], 10, 30)\n",
    "print(np.mean(np.square(images_norm - np.matmul(C, images_norm))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dsc' from 'C:\\\\Users\\\\aleks_000\\\\Desktop\\\\Mentorship\\\\!GitHub\\\\dsc.py'>"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dsc\n",
    "import importlib\n",
    "importlib.reload(dsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1\n",
      "300 -> 200\n",
      "epoch 0: global loss = 0.29537397623062134\n",
      "epoch 250: global loss = 0.04538171738386154\n",
      "epoch 500: global loss = 0.03850265219807625\n",
      "epoch 750: global loss = 0.03508767858147621\n",
      "epoch 1000: global loss = 0.03319395333528519\n",
      "Layer 2\n",
      "200 -> 150\n",
      "epoch 0: global loss = 0.13996924459934235\n",
      "epoch 250: global loss = 0.03345320373773575\n",
      "epoch 500: global loss = 0.028261490166187286\n",
      "epoch 750: global loss = 0.0266082976013422\n",
      "epoch 1000: global loss = 0.02575034089386463\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainC = True\n",
    "d = dsc.DeepSubspaceClustering(images_norm, C=C, trainC=trainC, hidden_dims=[200, 150, 200],\n",
    "                               lambda1=1.0, lambda2=10.0, lambda3=100.0, learning_rate=0.003, weight_init='sda-normal',\n",
    "                               weight_init_params=[1001, 0.006, images_norm.shape[0], 250],\n",
    "                               optimizer='Adam', decay='sqrt', sda_optimizer='Adam', sda_decay='sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0: global loss = 0.921984851360321\n",
      "epoch 50: global loss = 0.16839511692523956\n",
      "epoch 100: global loss = 0.1511012315750122\n",
      "epoch 150: global loss = 0.1394766867160797\n",
      "epoch 200: global loss = 0.1300310641527176\n",
      "epoch 250: global loss = 0.12194336205720901\n",
      "Wall time: 41.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#d.optimizer = optimize(d.cost, 0.0003, 'Adam', 'sqrt', d.global_step)\n",
    "d.train(batch_size=images_norm.shape[0], epochs=251, print_step=50)\n",
    "images_HM2 = d.result\n",
    "images_HM = d.reconstr\n",
    "trained_C = np.float64(d.outC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda3 - regularization on trained_C\n",
    "display_image(trained_C[:100, :100], 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(images_HM2[0], 10, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda1 - self-expressiveness\n",
    "display_image(np.matmul(trained_C, images_HM2)[0], 10, 15)\n",
    "print(np.mean(np.square(images_HM2 - np.matmul(trained_C, images_HM2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(np.mean(images_HM2, axis=0), 10, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(np.std(images_HM2, axis=0), 10, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#tSNE_2D(images_HM2, labels)\n",
    "#tSNE_3D(images_HM2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AE Reconstruction\n",
    "fig, ax = plt.subplots(2)\n",
    "\n",
    "index = 0;\n",
    "ax[0].imshow(images_norm[index].reshape((10, 30)));\n",
    "ax[1].imshow(images_HM[index].reshape((10, 30)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matlab SSC #2\n",
    "k = len(np.unique(labels))\n",
    "alpha = 100.0\n",
    "maxIter = 10\n",
    "if(trainC):\n",
    "    savemat('./temp.mat', mdict={'X': images_HM2})\n",
    "else:\n",
    "    savemat('./temp.mat', mdict={'C': trained_C})\n",
    "grps = eng.SSC_modified(k, 0, False, alpha, False, 1, 1e-20, maxIter, True, 0, givenC)\n",
    "C_after = loadmat(\"./temp.mat\")['C']\n",
    "labels_pred = np.asarray(grps, dtype=np.int32).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#tSNE_2D(images_HM2, labels_pred)\n",
    "#tSNE_3D(images_HM2, labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Perform clustering with SSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.36458333333333337\n",
      "NMI:  0.597934898916298\n",
      "ARI:  0.20502096981358237\n"
     ]
    }
   ],
   "source": [
    "from supporting_files.ji_zhang import err_rate\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "\n",
    "print(\"Accuracy: \", str(1-err_rate(labels, labels_pred)))\n",
    "print(\"NMI: \", str(nmi(labels, labels_pred, average_method=\"geometric\")))\n",
    "print(\"ARI: \", str(ari(labels, labels_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python alternative:\n",
    "from sklearn import cluster\n",
    "\n",
    "def post_proC(C, K, d, alpha):\n",
    "    # C: coefficient matrix, K: number of clusters, d: dimension of each subspace\n",
    "    n = C.shape[0]\n",
    "    C = 0.5*(C + C.T)\n",
    "    C = C - np.diag(np.diag(C)) + np.eye(n,n) # for sparse C, this step will make the algorithm more numerically stable\n",
    "    r = d*K + 1\n",
    "    U, S, _ = svds(C,r,v0 = np.ones(n))\n",
    "    U = U[:,::-1] \n",
    "    S = np.sqrt(S[::-1])\n",
    "    S = np.diag(S)\n",
    "    U = U.dot(S)\n",
    "    U = normalize(U, norm='l2', axis = 1)  \n",
    "    Z = U.dot(U.T)\n",
    "    Z = Z * (Z>0)\n",
    "    L = np.abs(Z ** alpha)\n",
    "    L = L/L.max()\n",
    "    L = 0.5 * (L + L.T)\n",
    "    spectral = cluster.SpectralClustering(n_clusters=K, eigen_solver='arpack', affinity='precomputed', assign_labels='discretize')\n",
    "    spectral.fit(L)\n",
    "    grp = spectral.fit_predict(L) + 1\n",
    "    return grp, L\n",
    "\n",
    "def best_map(L1,L2):\n",
    "    #L1 should be the labels and L2 should be the clustering number we got\n",
    "    Label1 = np.unique(L1)\n",
    "    nClass1 = len(Label1)\n",
    "    Label2 = np.unique(L2)\n",
    "    nClass2 = len(Label2)\n",
    "    nClass = np.maximum(nClass1,nClass2)\n",
    "    G = np.zeros((nClass,nClass))\n",
    "    for i in range(nClass1):\n",
    "        ind_cla1 = L1 == Label1[i]\n",
    "        ind_cla1 = ind_cla1.astype(float)\n",
    "        for j in range(nClass2):\n",
    "            ind_cla2 = L2 == Label2[j]\n",
    "            ind_cla2 = ind_cla2.astype(float)\n",
    "            G[i,j] = np.sum(ind_cla2 * ind_cla1)\n",
    "    m = Munkres()\n",
    "    index = m.compute(-G.T)\n",
    "    index = np.array(index)\n",
    "    c = index[:,1]\n",
    "    newL2 = np.zeros(L2.shape)\n",
    "    for i in range(nClass2):\n",
    "        newL2[L2 == Label2[i]] = Label1[c[i]]\n",
    "    return newL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred2 = best_map(post_proC(C_after, k, 0, alpha)[0], labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
