{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Coil20 data\n",
    "## Extract DSIFT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\aleks_000\\\\Desktop\\\\Mentorship\\\\!GitHub'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matlab.engine\n",
    "eng = matlab.engine.start_matlab()\n",
    "eng.cd(\"./SSC_ADMM_v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('./saved/raw/yaleB.mat', mdict={'X':images_raw, 'Y':labels})\n",
    "savemat('./saved/processed/yaleB.mat', mdict={'X':images_norm, 'Y':labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading YaleB...\n",
      "----------------\n",
      "Elapsed: 38.41 sec\n"
     ]
    }
   ],
   "source": [
    "from load import load_YaleB\n",
    "from img2matrix import single_img2dsift\n",
    "\n",
    "# I renamed files 1, 2.. to 01, 02..\n",
    "# so that they are in order here\n",
    "images_raw, labels = load_YaleB()\n",
    "images_dsift = [single_img2dsift(image) for image in images_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat(\"../2-DSCN/Data/COIL20.mat\")\n",
    "images_compressed = data['fea']\n",
    "labels_compressed = data['gnd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(images_raw[0].reshape((-1, 128)));\n",
    "ax[1].imshow(images_dsift[0].reshape((-1, 128)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(np.mean(images_raw, axis=0).reshape((-1, 128)));\n",
    "ax[1].imshow(np.mean(images_dsift, axis=0).reshape((-1, 128)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "idx = 0\n",
    "\n",
    "ax[0].imshow(np.mean(images_raw[72*idx:72*(idx+1)], axis=0).reshape((-1, 128)));\n",
    "ax[1].imshow(np.mean(images_dsift[72*idx:72*(idx+1)], axis=0).reshape((-1, 128)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(np.std(images_raw, axis=0).reshape((-1, 128)));\n",
    "ax[1].imshow(np.std(images_dsift, axis=0).reshape((-1, 128)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(images_compressed[0].reshape((-1, 32)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import tSNE_2D, tSNE_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images_raw_flat = images_raw.reshape(images_raw.shape[0], -1)\n",
    "tSNE_2D(images_compressed, labels_compressed)\n",
    "tSNE_3D(images_compressed, labels_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tSNE_2D(images_dsift, labels)\n",
    "tSNE_3D(images_dsift, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2350, 300)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "    \n",
    "pca = PCA(n_components=300, whiten=False, svd_solver='arpack', random_state=0)\n",
    "images_pca = pca.fit_transform(images_dsift)\n",
    "#OR\n",
    "#images_pca = pca.fit_transform(images_compressed)\n",
    "#labels = labels_compressed[:, 0]\n",
    "\n",
    "images_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_image(image, height, width):\n",
    "    print(np.min(image), np.max(image))\n",
    "    imgplot = plt.imshow(image.reshape((height, width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are reduced parameters - not supposed to look like anything\n",
    "display_image(images_pca[0], 10, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(np.mean(images_pca, axis=0), 10, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_image(np.std(images_pca, axis=0), 10, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tSNE_2D(images_pca, labels)\n",
    "tSNE_3D(images_pca, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize PCA output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types:\n",
    "# feature-wise - normalization occurs along one pixel of all images\n",
    "# image-wise - normalization occurs along all pixels of one image\n",
    "# all - normalization occurs along all pixels of all images\n",
    "\n",
    "# Methods:\n",
    "# standard - mean is set to 0, std is set to 1\n",
    "# [-1, 1] - min and max are used to linearly change the data range to [-1, 1]\n",
    "# unit-vector - each bin is divided by its euclidean distance\n",
    "\n",
    "#[BAD] feature, standard\n",
    "#images_norm = (images_pca - np.mean(images_pca, axis=0)) / np.std(images_pca, axis=0)\n",
    "# image, standard\n",
    "#images_norm = (images_pca - np.mean(images_pca, axis=1)[:, np.newaxis]) / np.std(images_pca, axis=1)[:, np.newaxis]\n",
    "# all, standard\n",
    "#images_norm = (images_pca - np.mean(images_pca)) / np.std(images_pca)\n",
    "\n",
    "\n",
    "#[BAD] feature, [-1, 1]\n",
    "#mmin = np.min(images_pca, axis=0)\n",
    "#mmax = np.max(images_pca, axis=0)\n",
    "#[BAD] image, [-1, 1]\n",
    "#mmin = np.min(images_pca, axis=1)[:, np.newaxis]\n",
    "#mmax = np.max(images_pca, axis=1)[:, np.newaxis]\n",
    "# all, [-1, 1]\n",
    "mmin = np.min(images_pca)\n",
    "mmax = np.max(images_pca)\n",
    "# FOR ALL:\n",
    "images_norm = (2*images_pca - mmax - mmin) / (mmax - mmin)\n",
    "\n",
    "#[BAD] feature, unit\n",
    "#images_norm = images_pca / np.sqrt(np.sum(images_pca*images_pca, axis=0))\n",
    "# image, unit\n",
    "#images_norm = images_pca / np.sqrt(np.sum(images_pca*images_pca, axis=1))[:, np.newaxis]\n",
    "# all, unit\n",
    "#images_norm = images_pca / np.sqrt(np.sum(images_pca*images_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# these are reduced parameters - not supposed to look like anything\n",
    "display_image(images_norm[0], 20, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(np.mean(images_norm, axis=0), 20, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_image(np.std(images_norm, axis=0), 20, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tSNE_2D(images_norm, labels)\n",
    "tSNE_3D(images_norm, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate C matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import supporting_files.sda as sda\n",
    "\n",
    "from supporting_files.helpers import optimize\n",
    "from scipy.io import savemat, loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matlab SSC #1\n",
    "savemat('./temp.mat', mdict={'X': images_norm})\n",
    "k = len(np.unique(labels))\n",
    "alpha = 999.0\n",
    "maxIter = 20\n",
    "eng.SSC_modified(k, 0, False, alpha, False, 1, 1e-20, maxIter, False)\n",
    "C = loadmat(\"./temp.mat\")['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_image(C[:110, :110], 110, 110)\n",
    "print(np.mean(np.square(C)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(np.matmul(C, images_norm)[0], 15, 20)\n",
    "print(np.mean(np.square(images_norm - np.matmul(C, images_norm))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dsc' from 'C:\\\\Users\\\\aleks_000\\\\Desktop\\\\Mentorship\\\\!GitHub\\\\dsc.py'>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dsc\n",
    "import importlib\n",
    "importlib.reload(dsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "trainC = False\n",
    "d = dsc.DeepSubspaceClustering(images_norm, C=None, trainC=trainC, hidden_dims=[500, 300, 500],\n",
    "                               lambda1=0.01, lambda2=0.01, lambda3=0.1, learning_rate=0.001, weight_init='sda-normal',\n",
    "                               weight_init_params=[2001, 0.001, images_norm.shape[0], 250],\n",
    "                               optimizer='Adam', decay='sqrt', sda_optimizer='Adam', sda_decay='sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "d.optimizer = optimize(d.cost, 0.0001, 'Adam', 'sqrt', d.global_step)\n",
    "d.train(batch_size=images_norm.shape[0], epochs=501, print_step=50)\n",
    "images_HM2 = d.result\n",
    "images_HM = d.reconstr\n",
    "trained_C = np.float64(d.outC)\n",
    "#best: 0.0001 - 0.000211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda3 - regularization on trained_C\n",
    "display_image(trained_C[:100, :100], 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(images_HM2[0], 15, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda1 - self-expressiveness\n",
    "display_image(np.matmul(trained_C, images_HM2)[0], 10, 15)\n",
    "print(np.mean(np.square(images_HM2 - np.matmul(trained_C, images_HM2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(np.mean(images_HM2, axis=0), 15, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(np.std(images_HM2, axis=0), 15, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tSNE_2D(images_HM2, labels)\n",
    "tSNE_3D(images_HM2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AE Reconstruction\n",
    "fig, ax = plt.subplots(2)\n",
    "\n",
    "index = 0;\n",
    "ax[0].imshow(images_norm[index].reshape((20, 50)));\n",
    "ax[1].imshow(images_HM[index].reshape((20, 50)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstr = pca.inverse_transform(((images_HM * (mmax - mmin)) + mmax + mmin) / 2)\n",
    "pca_reconstr = pca.inverse_transform(((images_norm * (mmax - mmin)) + mmax + mmin) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for Coil20\n",
    "\n",
    "# from scipy.io import savemat\n",
    "\n",
    "# images_raw_duck = images_raw[720:792]\n",
    "# images_HM2_duck = images_HM2[720:792]\n",
    "# reconstr_duck = reconstr[720:792]\n",
    "# pca_duck = images_norm[720:792]\n",
    "# pca_reconstr_duck = pca_reconstr[720:792]\n",
    "# savemat(\"../!Important/figures/AE_big\", mdict={'H0': images_raw_duck, 'HM2': images_HM2_duck, 'HM': reconstr_duck,\n",
    "#                                                'PCA': pca_duck, 'PCAr': pca_reconstr_duck})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matlab SSC #2\n",
    "k = len(np.unique(labels))\n",
    "alpha = 20.0\n",
    "maxIter = 50\n",
    "if(not trainC):\n",
    "    savemat('./temp.mat', mdict={'X': images_HM2})\n",
    "else:\n",
    "    savemat('./temp.mat', mdict={'C': trained_C})\n",
    "grps = eng.SSC_modified(k, 0, False, alpha, False, 1, 1e-20, maxIter, True, 0, trainC)\n",
    "C_after = loadmat(\"./temp.mat\")['C']\n",
    "labels_pred = np.asarray(grps, dtype=np.int32).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tSNE_2D(images_HM2, labels_pred)\n",
    "tSNE_3D(images_HM2, labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Perform clustering with SSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6659722222222222\n",
      "NMI:  0.7650959185842292\n",
      "ARI:  0.5830423165837528\n"
     ]
    }
   ],
   "source": [
    "from supporting_files.ji_zhang import err_rate\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "\n",
    "print(\"Accuracy: \", str(1-err_rate(labels, labels_pred)))\n",
    "print(\"NMI: \", str(nmi(labels, labels_pred, average_method=\"geometric\")))\n",
    "print(\"ARI: \", str(ari(labels, labels_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python alternative:\n",
    "from sklearn import cluster\n",
    "\n",
    "def post_proC(C, K, d, alpha):\n",
    "    # C: coefficient matrix, K: number of clusters, d: dimension of each subspace\n",
    "    n = C.shape[0]\n",
    "    C = 0.5*(C + C.T)\n",
    "    C = C - np.diag(np.diag(C)) + np.eye(n,n) # for sparse C, this step will make the algorithm more numerically stable\n",
    "    r = d*K + 1\n",
    "    U, S, _ = svds(C,r,v0 = np.ones(n))\n",
    "    U = U[:,::-1] \n",
    "    S = np.sqrt(S[::-1])\n",
    "    S = np.diag(S)\n",
    "    U = U.dot(S)\n",
    "    U = normalize(U, norm='l2', axis = 1)  \n",
    "    Z = U.dot(U.T)\n",
    "    Z = Z * (Z>0)\n",
    "    L = np.abs(Z ** alpha)\n",
    "    L = L/L.max()\n",
    "    L = 0.5 * (L + L.T)\n",
    "    spectral = cluster.SpectralClustering(n_clusters=K, eigen_solver='arpack', affinity='precomputed', assign_labels='discretize')\n",
    "    spectral.fit(L)\n",
    "    grp = spectral.fit_predict(L) + 1\n",
    "    return grp, L\n",
    "\n",
    "def best_map(L1,L2):\n",
    "    #L1 should be the labels and L2 should be the clustering number we got\n",
    "    Label1 = np.unique(L1)\n",
    "    nClass1 = len(Label1)\n",
    "    Label2 = np.unique(L2)\n",
    "    nClass2 = len(Label2)\n",
    "    nClass = np.maximum(nClass1,nClass2)\n",
    "    G = np.zeros((nClass,nClass))\n",
    "    for i in range(nClass1):\n",
    "        ind_cla1 = L1 == Label1[i]\n",
    "        ind_cla1 = ind_cla1.astype(float)\n",
    "        for j in range(nClass2):\n",
    "            ind_cla2 = L2 == Label2[j]\n",
    "            ind_cla2 = ind_cla2.astype(float)\n",
    "            G[i,j] = np.sum(ind_cla2 * ind_cla1)\n",
    "    m = Munkres()\n",
    "    index = m.compute(-G.T)\n",
    "    index = np.array(index)\n",
    "    c = index[:,1]\n",
    "    newL2 = np.zeros(L2.shape)\n",
    "    for i in range(nClass2):\n",
    "        newL2[L2 == Label2[i]] = Label1[c[i]]\n",
    "    return newL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred2 = best_map(post_proC(C_after, k, 0, alpha)[0], labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
